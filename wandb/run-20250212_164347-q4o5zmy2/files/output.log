{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 15}, 'horizon': 40, 'node_weight': 'steiner_covering', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'domains': 'single_room', 'stochasticity': 0}, 'alg': {'gamma': 1, 'type': 'M', 'ent_coef': 0.0, 'epochs': 150, 'lr': 0.005}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 1}, 'visu': {'wb': 'online', 'a': 1}}
x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001, 14.4999, 14.5001]
y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]
/Users/devarora/ml/submodular_nn/dqn.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(
/Users/devarora/ml/submodular_nn/dqn.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(
/Users/devarora/ml/submodular_nn/replay_memory.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(reward).to(self.device), torch.tensor(next_state).float().to(self.device),
tensor([6])
0
/Users/devarora/ml/submodular_nn/replay_memory.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(reward).to(self.device), torch.tensor(next_state).float().to(self.device),
tensor([4])
0
tensor([5])
0
tensor([5])
0
tensor([7])
0
tensor([6])
4.210918217897415
tensor([4])
5.467446282505989
tensor([5])
5.114260792732239
tensor([1])
4.454602226614952
tensor([2])
3.9425052404403687
tensor([5])
3.9507423043251038
tensor([5])
3.834224671125412
tensor([6])
4.167650073766708
tensor([4])
3.898360460996628
tensor([5])
3.780240476131439
tensor([4])
3.847936287522316
tensor([5])
3.677881807088852
tensor([4])
3.638808950781822
tensor([5])
3.4821376651525497
tensor([6])
3.5693639367818832
tensor([5])
3.657620131969452
tensor([4])
3.769421085715294
tensor([4])
3.547732576727867
tensor([4])
3.4875071942806244
tensor([4])
3.6598443686962128
tensor([4])
3.43837733566761
tensor([8])
3.3840482980012894
tensor([10])
3.511077508330345
tensor([9])
3.577105864882469
tensor([9])
3.661736488342285
tensor([11])
3.6867375522851944
tensor([10])
3.919786974787712
tensor([9])
3.7940837740898132
tensor([9])
3.720951169729233
tensor([10])
3.746059387922287
tensor([10])
3.9203129410743713
tensor([9])
3.8265877217054367
tensor([9])
3.9193273335695267
tensor([9])
3.912923827767372
tensor([9])
3.8848390728235245
tensor([8])
3.956934317946434
tensor([9])
3.9850242286920547
tensor([9])
3.996688425540924
tensor([12])
4.070515647530556
tensor([9])
4.012702718377113
tensor([9])
3.9188781678676605
tensor([9])
4.038823619484901
tensor([9])
3.981181725859642
tensor([10])
4.194942682981491
tensor([9])
4.052738755941391
tensor([10])
4.067553818225861
tensor([10])
4.167541816830635
tensor([9])
4.03970967233181
tensor([8])
4.098453998565674
tensor([9])
4.056759238243103
tensor([9])
4.282133728265762
tensor([9])
4.073398217558861
tensor([9])
4.217838734388351
tensor([9])
4.154771000146866
tensor([10])
4.205283015966415
tensor([9])
4.1902966350317
tensor([9])
4.324762761592865
tensor([9])
4.392208859324455
tensor([9])
4.432097569108009
tensor([9])
4.4636131674051285
tensor([10])
4.434376358985901
tensor([9])
4.355025440454483
tensor([9])
4.4361314326524734
tensor([9])
4.466093927621841
tensor([9])
4.577175125479698
tensor([9])
4.510993853211403
tensor([9])
4.616756737232208
tensor([9])
4.495754137635231
tensor([9])
4.604415729641914
tensor([9])
4.648917034268379
tensor([9])
4.622521251440048
tensor([9])
4.6997219026088715
tensor([9])
4.718445956707001
tensor([9])
4.707588732242584
tensor([9])
4.751196801662445
tensor([9])
4.720387548208237
tensor([9])
4.703973889350891
tensor([9])
4.7540827095508575
tensor([9])
4.7325592786073685
tensor([9])
4.747216895222664
tensor([9])
4.721358954906464
tensor([9])
4.780214682221413
tensor([9])
4.756348058581352
tensor([9])
4.757105678319931
tensor([9])
4.7304831594228745
tensor([9])
4.782051354646683
tensor([9])
4.735955476760864
tensor([9])
4.766090199351311
tensor([9])
4.758241176605225
tensor([9])
4.780074551701546
tensor([9])
4.742461234331131
tensor([9])
4.717266917228699
tensor([9])
4.720871865749359
tensor([9])
4.748134449124336
tensor([9])
4.76417464017868
tensor([9])
4.767150595784187
tensor([9])
4.747834965586662
tensor([9])
4.7538181245327
tensor([9])
4.740733563899994
tensor([9])
4.7346441596746445
tensor([9])
4.751846998929977
tensor([9])
4.753996327519417
tensor([9])
4.7409862875938416
tensor([9])
4.772661700844765
tensor([9])
4.759319826960564
tensor([9])
4.746183782815933
tensor([9])
4.757995083928108
tensor([9])
4.7304069846868515
tensor([9])
4.726173996925354
tensor([9])
4.749241009354591
tensor([9])
4.747931718826294
tensor([9])
4.741235211491585
tensor([9])
4.737267315387726
tensor([9])
4.723036378622055
tensor([9])
4.75460147857666
tensor([9])
4.740764021873474
tensor([9])
4.736110597848892
tensor([9])
4.726780399680138
tensor([9])
4.740352526307106
tensor([9])
4.751533210277557
tensor([9])
4.736840143799782
tensor([9])
4.739684358239174
tensor([9])
4.739044189453125
tensor([9])
4.723352909088135
tensor([9])
4.756646037101746
tensor([9])
4.729313492774963
tensor([9])
4.742875173687935
tensor([9])
4.741476684808731
tensor([9])
4.719667494297028
tensor([9])
4.752210170030594
tensor([9])
4.712526544928551
tensor([9])
4.745472937822342
tensor([9])
4.736580267548561
tensor([9])
4.714913159608841
tensor([9])
4.751726150512695
tensor([9])
4.7452011704444885
tensor([9])
4.735387921333313
tensor([9])
4.734570398926735
tensor([9])
4.7392595410346985
tensor([9])
4.749691009521484
tensor([9])
4.7423475831747055
tensor([9])
4.7193721532821655
tensor([9])
4.745808348059654
tensor([9])
4.72959640622139
tensor([9])
4.754326954483986
